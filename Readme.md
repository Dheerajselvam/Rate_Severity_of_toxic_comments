#Rate_Severity_of_toxic_comments
Toxic behavior on social media is expected, but it becomes increasingly unacceptable. Toxicity within the social realm can be described as the spread of unnecessary negativity or hatred that adversely affects the people it encounters. Toxic people spread malicious intent on the Internet and try to abuse others in discussions. A study by (Kwak et al)[1]. showed toxic behavior in online team competition  games. They found that the outcome of the match was related to the development of toxic behavior. Toxic comments on social sites such as Twitter can be found on topics that are extremely difficult to discuss, such as Brexit, climate change, abortion, vaccines, and the US presidential election. Toxic behavior is more common on such topics due to its divisive nature. When discussing such topics, people tend to have different opinions, which can lead to division (D. Yin et al., 2009)[2]. 
The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable. Most NLP techniques rely on machine learning to derive meaning from human languages. Machine learning explores the construction and study of algorithms that can learn from and make predictions on data. Such algorithms operate by building a model for example inputs in order to make data-driven predictions or decisions, rather than following strictly static program instructions.
Since detection of Toxic comments and their classification has already in application in many online platforms, this project aims to rank the severity of the toxic comments. In this project, we will tackle the Jigsaw rate severity of toxic comments Challenge. When humans are asked to look at individual comments, without any context, to decide which ones are toxic and which ones are not, it is not an easy work. Also, each person will have a different threshold for toxicity. If Majority vote is taken to make a decision on it researchers have pointed out that this discards meaningful information. Therefore, it is a much easier to people decide which of two comments they find more toxic. 

In this project, we will use a ranking model called Bert that learns contextual embedding, which has been applied to capture complex query-document relations for search ranking and neural methods, i.e. RNN and CNN. 
